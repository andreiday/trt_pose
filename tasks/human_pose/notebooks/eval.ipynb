{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pycocotools.coco\n",
    "import pycocotools.cocoeval\n",
    "import os\n",
    "import torch\n",
    "import PIL.Image\n",
    "import torchvision\n",
    "import torchvision.transforms\n",
    "import trt_pose.plugins\n",
    "import trt_pose.models\n",
    "import trt_pose.coco\n",
    "import torch2trt\n",
    "import tqdm\n",
    "import json\n",
    "from trt_pose.parse_objects import ParseObjects\n",
    "import torch2trt\n",
    "from torch2trt import TRTModule\n",
    "device = torch.device('cuda')\n",
    "import pycocotools"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "model = TRTModule()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "model.load_state_dict(torch.load('/home/jetson/jetson/projects/trt_pose/tasks/human_pose/weights/resnet18_baseline_att_256x256_A_epoch_81_trt.pth'))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "data = torch.zeros((1, 3, 256, 256)).cuda()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "model = model.cuda().eval()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "cmap, paf = model(torch.zeros((1, 3, 256, 256)).cuda())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "cmap.shape\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 18, 56, 56])"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "paf.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 42, 56, 56])"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "!ls"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "annotations  eval.ipynb  live_demo.ipynb  pose_estimation_training.ipynb\n",
      "^C\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "IMAGE_SHAPE = (256, 256)\n",
    "images_dir = '../val2017'\n",
    "annotation_file = '../annotations/person_keypoints_val2017_modified.json'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "cocoGtTmp = pycocotools.coco.COCO('../annotations/person_keypoints_val2017_modified.json')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=2.59s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "topology = trt_pose.coco.coco_category_to_topology(cocoGtTmp.cats[1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "cocoGt = pycocotools.coco.COCO('../annotations/person_keypoints_val2017.json')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.06s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "catIds = cocoGt.getCatIds('person')\n",
    "imgIds = cocoGt.getImgIds(catIds=catIds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "parse_objects = ParseObjects(topology, cmap_threshold=0.05, link_threshold=0.1, cmap_window=11, line_integral_samples=7, max_num_parts=100, max_num_objects=100)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "results = []\n",
    "\n",
    "for n, imgId in enumerate(imgIds):\n",
    "    \n",
    "    # read image\n",
    "    img = cocoGt.imgs[imgId]\n",
    "    img_path = os.path.join(images_dir, img['file_name'])\n",
    "\n",
    "    image = PIL.Image.open(img_path).convert('RGB').resize(IMAGE_SHAPE)\n",
    "    data = transform(image).cuda()[None, ...]\n",
    "\n",
    "    cmap, paf = model(data)\n",
    "    cmap, paf = cmap.cpu(), paf.cpu()\n",
    "\n",
    "#     object_counts, objects, peaks, int_peaks = postprocess(cmap, paf, cmap_threshold=0.05, link_threshold=0.01, window=5)\n",
    "#     object_counts, objects, peaks = int(object_counts[0]), objects[0], peaks[0]\n",
    "    \n",
    "    object_counts, objects, peaks = parse_objects(cmap, paf)\n",
    "    object_counts, objects, peaks = int(object_counts[0]), objects[0], peaks[0]\n",
    "\n",
    "    for i in range(object_counts):\n",
    "        object = objects[i]\n",
    "        score = 0.0\n",
    "        kps = [0]*(17*3)\n",
    "        x_mean = 0\n",
    "        y_mean = 0\n",
    "        cnt = 0\n",
    "        for j in range(17):\n",
    "            k = object[j]\n",
    "            if k >= 0:\n",
    "                peak = peaks[j][k]\n",
    "                x = round(float(img['width'] * peak[1]))\n",
    "                y = round(float(img['height'] * peak[0]))\n",
    "                score += 1.0\n",
    "                kps[j * 3 + 0] = x\n",
    "                kps[j * 3 + 1] = y\n",
    "                kps[j * 3 + 2] = 2\n",
    "                x_mean += x\n",
    "                y_mean += y\n",
    "                cnt += 1\n",
    "\n",
    "        ann = {\n",
    "            'image_id': imgId,\n",
    "            'category_id': 1,\n",
    "            'keypoints': kps,\n",
    "            'score': score / 17.0\n",
    "        }\n",
    "        results.append(ann)\n",
    "    if n % 100 == 0:\n",
    "        print('%d / %d' % (n, len(imgIds)))\n",
    "#     break\n",
    "        \n",
    "with open('results.json', 'w') as f:\n",
    "    json.dump(results, f)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 / 2693\n",
      "100 / 2693\n",
      "200 / 2693\n",
      "300 / 2693\n",
      "400 / 2693\n",
      "500 / 2693\n",
      "600 / 2693\n",
      "700 / 2693\n",
      "800 / 2693\n",
      "900 / 2693\n",
      "1000 / 2693\n",
      "1100 / 2693\n",
      "1200 / 2693\n",
      "1300 / 2693\n",
      "1400 / 2693\n",
      "1500 / 2693\n",
      "1600 / 2693\n",
      "1700 / 2693\n",
      "1800 / 2693\n",
      "1900 / 2693\n",
      "2000 / 2693\n",
      "2100 / 2693\n",
      "2200 / 2693\n",
      "2300 / 2693\n",
      "2400 / 2693\n",
      "2500 / 2693\n",
      "2600 / 2693\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "with open('results.json', 'w') as f:\n",
    "    json.dump(results, f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "cocoDt = cocoGt.loadRes('results.json')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=3.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "cocoEval = pycocotools.cocoeval.COCOeval(cocoGt, cocoDt, 'keypoints')\n",
    "cocoEval.params.imgIds = imgIds\n",
    "cocoEval.params.catIds = [1]\n",
    "cocoEval.evaluate()\n",
    "cocoEval.accumulate()\n",
    "cocoEval.summarize()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Running per image evaluation...\n",
      "Evaluate annotation type *keypoints*\n",
      "DONE (t=30.23s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.45s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.185\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.365\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.165\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = 0.078\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.330\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.245\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.410\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.241\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = 0.083\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.467\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}